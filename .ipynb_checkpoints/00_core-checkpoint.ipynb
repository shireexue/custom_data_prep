{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom_data_prep\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "data = {'Name':['Tom', 'nick', 'krish', 'jack','Amy','Lily','Carol'],\n",
    "        'Age':['33','22','41','12','34','21','60'],\n",
    "        'Country':['US','AU','UK','CN','US','JP','NZ'],\n",
    "        'target':[1,0,0,1,0,1,1]\n",
    "       }\n",
    "\n",
    "df=pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def collapse_level(df,categorical_vars,keep_level=20):\n",
    "    \"\"\"Collapse levels for categorical variables with high cardinality.\n",
    "\n",
    "    This operation identifies categorical variables with high cardinality and combine into levels that have \n",
    "    both high target rates and frequency. The number of levels to keep is defined by user.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe, required\n",
    "        Dataframe to process\n",
    "\n",
    "    categorical_vars : list, required\n",
    "        A list of categorical variables that will go through the treatment process\n",
    "\n",
    "    keep_level : int, required\n",
    "        Used to select high cardinality variables which exceed the specified level and collapse existing\n",
    "        levels to this range.\n",
    "\n",
    "    \"\"\"        \n",
    "\n",
    "    numclasses={}\n",
    "    catclasses={}\n",
    "    for c in categorical_vars:\n",
    "        uni_cnt=(len(np.unique(df[[c]])))\n",
    "        numclasses[c]=uni_cnt\n",
    "        if uni_cnt>keep_level:\n",
    "            df_group=df.groupby(c).agg(pred_rate=('target','mean'),cnt=('Name','count')).reset_index()\\\n",
    "                       .sort_values(['cnt','pred_rate'],ascending=False)[:keep_level-1]\n",
    "            keep_list=df_group.iloc[:,0].tolist()\n",
    "            df[c]=np.where(~df[c].isin(keep_list),'OTHER',df[c])\n",
    "            catclasses[c]=df.loc[:,c].unique().tolist()\n",
    "\n",
    "    return df,catclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class cat_treat:\n",
    "    \n",
    "    def __init__(self, df, categorical_vars):\n",
    "        \n",
    "        #attributes\n",
    "        self.df=df\n",
    "        self.categorical_vars=categorical_vars\n",
    "        \n",
    "    def reduce_cardinality(self,df,categorical_vars,keep_level=20):\n",
    "        \"\"\"Collapse levels for categorical variables with high cardinality.\n",
    "\n",
    "        This operation identifies categorical variables with high cardinality and combine into levels that have \n",
    "        both high target rates and frequency. The number of levels to keep is defined by user.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        df : pandas dataframe, required\n",
    "            Dataframe to process\n",
    "\n",
    "        categorical_vars : list, required\n",
    "            A list of categorical variables that will go through the treatment process\n",
    "\n",
    "        keep_level : int, required\n",
    "            Used to select high cardinality variables which exceed the specified level and collapse existing\n",
    "            levels to this range.\n",
    "\n",
    "        \"\"\"          \n",
    "        return collapse_level(self.df,self.categorical_vars,keep_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"cat_treat.reduce_cardinality\" class=\"doc_header\"><code>cat_treat.reduce_cardinality</code><a href=\"__main__.py#L11\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>cat_treat.reduce_cardinality</code>(**`df`**, **`categorical_vars`**, **`keep_level`**=*`20`*)\n",
       "\n",
       "Collapse levels for categorical variables with high cardinality.\n",
       "\n",
       "This operation identifies categorical variables with high cardinality and combine into levels that have \n",
       "both high target rates and frequency. The number of levels to keep is defined by user.\n",
       "\n",
       "Parameters\n",
       "-----------\n",
       "df : pandas dataframe, required\n",
       "    Dataframe to process\n",
       "\n",
       "categorical_vars : list, required\n",
       "    A list of categorical variables that will go through the treatment process\n",
       "\n",
       "keep_level : int, required\n",
       "    Used to select high cardinality variables which exceed the specified level and collapse existing\n",
       "    levels to this range."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(cat_treat.reduce_cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "o = cat_treat(df,['Country'])\n",
    "\n",
    "df_new=o.reduce_cardinality(df,categorical_vars=['Country'],keep_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    Name Age Country  target\n",
       " 0    Tom  33      US       1\n",
       " 1   nick  22   OTHER       0\n",
       " 2  krish  41   OTHER       0\n",
       " 3   jack  12      CN       1\n",
       " 4    Amy  34      US       0\n",
       " 5   Lily  21   OTHER       1\n",
       " 6  Carol  60   OTHER       1,\n",
       " {'Country': ['US', 'OTHER', 'CN']})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
